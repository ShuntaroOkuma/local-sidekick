# Local Sidekick PoC: バックエンド選定レポート

## 概要

Local Sidekickは、macOS上でカメラ映像とPC利用状況からユーザーの集中状態（focused / drowsy / distracted / away / idle）をリアルタイム推定する常駐アプリである。

本レポートでは、オンデバイスLLMによる状態推定の技術検証（PoC）において、**6つのバックエンド構成**を3ラウンドのシナリオテストで比較評価し、最終的に **llama-cpp-python（テキストモード）** を採用した経緯をまとめる。

## 検証環境

- **マシン**: Apple Silicon Mac（M3-M4 / 16-36GB RAM）
- **OS**: macOS Sequoia
- **モデル**: Qwen2.5-3B-Instruct（Q4_K_M量子化, ~2GB）
- **カメラ**: 内蔵Webカメラ（640x480）
- **顔特徴量**: MediaPipe FaceMesh（478ランドマーク）

## 検証したバックエンド構成

| # | 構成 | 推論方式 | モデルサイズ |
|---|------|----------|-------------|
| 1 | llama-cpp-python テキスト | 顔特徴量JSON → LLM | 3B |
| 2 | mlx-lm テキスト | 顔特徴量JSON → LLM | 3B |
| 3 | LM Studio テキスト | 顔特徴量JSON → API | 3B-27B |
| 4 | llama-cpp-python ビジョン | カメラ画像 → VLM | 2B |
| 5 | mlx-vlm ビジョン | カメラ画像 → VLM | 2B |
| 6 | LM Studio ビジョン | カメラ画像 → API | 8B-27B |

## テスト方法

4つのシナリオを各バックエンドで実行し、LLMの出力と実際の状態が一致するかを評価した。

| シナリオ | 動作 | 期待される状態 |
|----------|------|---------------|
| A: 集中 | 画面を正面から見つめ、自然に作業する | focused |
| B: 眠気 | 目を閉じる、あくび、うつむく | drowsy |
| C: よそ見 | スマホを見る、横を向く、そわそわする | distracted |
| D: 離席 | カメラの前から離れる | away |

---

## ラウンド1: 初期評価

### 結果サマリー

| バックエンド | focused | drowsy | distracted | away | 正答率 |
|-------------|---------|--------|------------|------|--------|
| llama_cpp テキスト | △ | △ | x | o | ~50% |
| mlx テキスト | △ | △ | x | o | ~70% |
| LM Studio テキスト | x | x | x | o | ~30% |
| llama_cpp ビジョン | - | x(全てdrowsy) | x | - | ~10% |
| mlx ビジョン | - | x(unknown) | x | △ | ~20% |
| LM Studio ビジョン | o | △ | △ | o | ~70% |

（o=正答, △=部分的に正答, x=誤判定）

### 判明した問題

- テキストモード全般: drowsyとfocusedの区別がつかない、distractedが一度も出ない
- ビジョン llama_cpp (2B): 全てdrowsyと判定し使い物にならない
- ビジョン mlx (2B): "sitting"や"unknown"など仕様外の応答
- LM Studio テキスト: focusedでもdistracted/drowsyを頻発

### 実施した改善

1. **プロンプト改善**: ルール優先順位の明確化、few-shotサンプルの追加
2. **特徴量強化**: EARウィンドウ統計、頭部動き統計、視線離脱率の追加
3. **ルールベース分類器の導入**: 明確なケースはLLMを呼ばずに決定論的に判定
4. **PC利用状況モニタのバグ修正**: アクティブアプリ取得、アイドル検出の修正

---

## ラウンド2: 改善後の再評価

### 結果サマリー

| バックエンド | focused | drowsy | distracted | away | 正答率 |
|-------------|---------|--------|------------|------|--------|
| llama_cpp テキスト | **x(全てdistracted)** | o | o(9/10) | o | ~75% |
| mlx テキスト | **x(全てdistracted)** | o | o(7/10) | o | ~70% |
| LM Studio テキスト | **x(全てdistracted)** | o | o(7/10) | o | ~70% |
| llama_cpp ビジョン | o | x(focusedのみ) | x(focusedのみ) | o | ~50% |
| mlx ビジョン | x(unknown) | x | x | o | ~25% |
| LM Studio ビジョン | o | o | △(不安定) | o | **~85%** |

### 重要な発見

**テキストモード全バックエンドで focused → distracted の誤判定が100%発生**。モデルサイズ（3B～27B）やバックエンドに関係なく同じ結果だったため、モデル依存ではなく**入力データの構造的問題**と判断。

**根本原因: ジンバルロック**

`cv2.solvePnP` によるヘッドポーズ推定で、オイラー角分解時にpitch値が ±180° にオフセットされる問題を発見。

```
正面を向いている状態:
  期待値: pitch ≈ 0°, yaw ≈ -9°
  実際値: pitch ≈ 167°, yaw ≈ -9°  ← ジンバルロック
```

この異常なpitch値が以下の連鎖障害を引き起こしていた:

```
pitch=167° → |pitch|>15 → gaze_off_screen_ratio=1.0（常に「画面外」）
           → |pitch|>10 → focused ルール不成立 → LLMフォールバック
           → LLM「pitch=167 → distracted」と判定
```

**ビジョンモードの発見**: LM Studio + 8B以上のモデルで最も高い精度を達成したが、推論に3-4秒/回かかりリソース消費が大きい。2-3Bのビジョンモデルでは実用的な精度が出ない。

---

## ラウンド3: ジンバルロック修正後

### 修正内容

```python
# solvePnPの座標系ずれを補正
if pitch_deg > 90:
    pitch_deg -= 180    # 167° → -13°（正面やや上向き）
elif pitch_deg < -90:
    pitch_deg += 180    # -148° → 32°（下向き）
```

加えて、頭部動き統計のウィンドウを60秒→15秒に短縮し、一度のよそ見が長時間残り続ける問題も修正。

### 結果サマリー

| バックエンド | focused | drowsy | distracted | away | 正答率 |
|-------------|---------|--------|------------|------|--------|
| **llama_cpp テキスト** | **o** | **o** | **o** | **o** | **~90%** |
| **mlx テキスト** | **o** | **o** | **o** | **o** | **~90%** |

テキストモードの両バックエンドで全シナリオが正しく判定されるようになった。ビジョンモードの追加検証は不要と判断。

---

## パフォーマンス比較

### LLMレイテンシー

| バックエンド | 平均 | P50 | P95 | ルール判定率 |
|-------------|------|-----|-----|-------------|
| **llama_cpp テキスト** | **532ms** | **498ms** | **732ms** | **78%** |
| mlx テキスト | 667ms | 687ms | 744ms | 72% |
| LM Studio テキスト | ~800ms | - | - | - |
| llama_cpp ビジョン | 285ms | - | - | 33% |
| mlx ビジョン | 1,116ms | - | - | 50% |
| LM Studio ビジョン | 2,713ms | - | - | 25% |

※ ルール判定率が高いほど、LLM呼び出しなし（0ms）で応答できる割合が多い

### リソース消費（推定）

| 構成 | モデルメモリ | 推論GPU負荷 | 同時利用可能性 |
|------|------------|------------|---------------|
| テキスト 3B (llama_cpp/mlx) | ~2GB | 低（5秒間隔） | 通常作業と共存可 |
| ビジョン 8B (LM Studio) | ~6-8GB | 高（3-4秒/回） | 作業に影響あり |

---

## 採用判断: llama-cpp-python テキストモード

### 選定理由

| 評価軸 | llama_cpp | mlx | LM Studio ビジョン |
|--------|-----------|-----|--------------------|
| 精度（ラウンド3） | ~90% | ~90% | ~85% |
| LLMレイテンシー | **532ms** | 667ms | 2,713ms |
| メモリ使用量 | ~2GB | ~2GB | ~6-8GB |
| ルール判定率 | **78%** | 72% | 25% |
| デプロイ容易性 | **GGUFファイル1つ** | HF初回DL必要 | LM Studio起動必要 |
| クロスプラットフォーム | **Linux/Win/Mac** | Mac専用 | Mac/Linux |

**llama_cppを選択した決め手:**

1. **最速のレイテンシー** — LLMフォールバック時に平均532ms（mlxより25%高速）
2. **最高のルール判定率** — 78%のケースでLLM呼び出し不要（0ms応答）
3. **デプロイの簡潔さ** — GGUFファイル1つで完結、外部サービス不要
4. **将来の展開性** — Linux/Windowsにも対応可能（mlxはApple Silicon専用）

### ビジョンモードを不採用とした理由

LM Studio + 8Bビジョンモデルが最も高い精度（~85%）を示したが、以下の理由で不採用:

- 推論に3-4秒かかり、リアルタイム性に欠ける
- 8B以上のモデルが必要（2-3Bでは精度不足）で、メモリ6-8GBを消費
- LM Studioの常時起動が必要
- テキストモード + ジンバルロック修正で同等以上の精度（~90%）を達成

---

## アーキテクチャ概要

最終的に採用したアーキテクチャ:

```
┌─────────────┐    ┌──────────────┐    ┌─────────────────┐
│  Webカメラ   │───>│  MediaPipe   │───>│  特徴量抽出     │
│  640x480     │    │  FaceMesh    │    │  EAR/MAR/HeadPose│
└─────────────┘    └──────────────┘    └────────┬────────┘
                                                │
                                       ┌────────v────────┐
                                       │ ルールベース     │──── 78%のケース
                                       │ 分類器           │     (0ms, 決定論的)
                                       └────────┬────────┘
                                                │ 曖昧なケースのみ
                                       ┌────────v────────┐
                                       │ llama-cpp-python │──── 22%のケース
                                       │ Qwen2.5-3B      │     (~500ms)
                                       │ (Q4_K_M, Metal)  │
                                       └─────────────────┘

┌─────────────┐    ┌──────────────────┐
│  PC利用状況  │───>│  ルール + LLM    │──── focused/distracted/idle
│  モニター    │    │  (同じモデル)    │
└─────────────┘    └──────────────────┘
```

### 2段階分類の効果

| 段階 | 処理 | レイテンシー | カバー率 |
|------|------|-------------|---------|
| 第1段階: ルールベース | 閾値ベースの決定論的判定 | 0ms | ~78% |
| 第2段階: LLMフォールバック | 曖昧なケースのみLLM呼び出し | ~500ms | ~22% |

ルールベース分類器が明確なケース（目を閉じている→drowsy、顔が検出されない→away等）を即座に処理し、LLMは判断が難しいグレーゾーンにのみ使用される。

---

## 発見した技術的課題と解決策

| 課題 | 原因 | 解決策 |
|------|------|--------|
| focused→distracted誤判定(100%) | solvePnPのジンバルロックでpitch≈±180° | pitch/rollの正規化（±90°超をアンラップ） |
| distracted→focused復帰不能 | 60sウィンドウにmax/count値が残り続ける | 頭部動き統計を15sサブウィンドウで計算 |
| focusedが全く出ない(300s) | カメラがモニター上部にあり自然なpitch≈-17° | gaze_off_screen/focused判定のpitchしきい値を15°→25°に緩和 |
| VSCodeが"Electron"と表示 | NSWorkspaceがプロセス名を返す | osascript + `displayed name`に変更 |
| is_idleが常にfalse | CGEventSourceがマウス微振動を検知 | kCGEventKeyDown + kCGEventLeftMouseDownに限定 |
| LLMがis_idle=falseでもidle判定 | プロンプトの曖昧さ | FORBIDDEN ルールの明示的追加 |
| app_switchesが減らない | 60sウィンドウでカウント | アプリ切替は30sウィンドウに短縮 |

---

## テスト4: 総合テスト（カメラ + PC利用状況の併用）

ラウンド3の修正後に300秒の総合テストを実施。カメラ判定（5秒間隔）とPC利用状況判定（30秒間隔）を同時に実行し、両者の挙動を比較した。

### カメラ判定の結果（60分析 / 297秒）

| 状態 | 回数 | 割合 |
|------|------|------|
| focused | 30 | 50% |
| distracted | 23 | 38% |
| away | 6 | 10% |
| drowsy | 1 | 2% |

- **focusedの正常判定を確認**: 最初の21回（~100秒）が連続focusedとなり、pitchしきい値修正が有効に機能
- **自然な状態遷移**: focused → drowsy → distracted → focused復帰 → away → focused復帰のサイクルを正しく検出
- **ルール判定率: 95%**（57/60がルール判定、LLMフォールバックは3回のみ）
- **LLMレイテンシー**: 493〜786ms（呼び出し3回の平均: 649ms）

### PC利用状況の結果（10分析 / 275秒）

| # | 状態 | ソース | アプリ | 特記 |
|---|------|--------|--------|------|
| 1 | focused | llm | Code | 起動直後、入力なし |
| 2-4 | focused | rule | Code | タイピング中（54〜309キー入力） |
| 5 | focused | llm | iTerm2 | app_switches=4（メール/Brave切替あり） |
| 6-7 | focused | llm | Code | LINE/Brave/iTerm2切替、confidence=0.7 |
| 8 | focused | llm | Code | idle=49.1s（60sしきい値未満） |
| 9 | **idle** | rule | Code | idle=79.8s → 正しくidle判定 |
| 10 | **idle** | rule | Code | idle=110.0s → 正しくidle判定 |

- **focused/idle切替が正確**: 60秒アイドルしきい値で正しく遷移
- **アプリ切替の記録**: メール、Brave Browser、LINE、iTerm2、Codeの切替を正確に検出
- **ルール判定率: 50%**（5/10）
- **distracted検出の限界**: app_switches=4でもfocused判定となり、PC操作だけではdistractedの検出が困難

### 判明した特性の違い

| 観点 | カメラ判定 | PC利用状況 |
|------|-----------|-----------|
| focused検出 | 頭部姿勢・目の開き具合から判定 | タイピング量・アプリ集中から判定 |
| drowsy検出 | **PERCLOS・EAR・あくびで高精度** | 検出不可 |
| distracted検出 | **頭の向き・動き量で高精度** | アプリ切替だけでは検出困難 |
| away検出 | **顔未検出で即座に判定** | 検出不可 |
| idle検出 | 検出不可 | **60秒操作なしで高精度** |
| 応答速度 | 5秒間隔、95%が0ms | 30秒間隔、50%が0ms |

---

## 統合方針: カメラをベース、PC利用状況を補助

テスト4の結果から、**カメラ判定をプライマリ、PC利用状況をセカンダリ**とする統合方針を決定した。

### 理由

**カメラをベースにすべき理由:**
- 5秒間隔でリアルタイムに4状態（focused/drowsy/distracted/away）を検出可能
- ルール判定率95%により、ほぼ0msで応答
- 物理的な状態（目の閉じ具合、頭の向き、離席）を直接観測

**PC利用状況が補助に適している理由:**
- distracted検出が弱い（アプリ切替=4回でもfocused判定）
- 得意なのはidle検出（60秒操作なし）とfocused確認（タイピング活動）
- 30秒間隔と粗く、状態変化への反応が遅い

### 統合ルール

| カメラ判定 | PC利用状況 | 最終判定 | 備考 |
|-----------|-----------|---------|------|
| focused | focused / typing | **focused** | 高確信、両方一致 |
| focused | idle | **idle** | PC側が支配（操作停止は確実な情報） |
| drowsy | any | **drowsy** | カメラが支配（身体状態はPCでは取れない） |
| distracted | focused / typing | **focused**に上書き検討可 | タイピング中のよそ見は一時的と判断 |
| distracted | distracted | **distracted** | 高確信、両方一致 |
| away | any | **away** | カメラが支配（離席は確実な情報） |

### 統合アーキテクチャ

```
┌─────────────┐    ┌──────────────┐    ┌─────────────────┐
│  Webカメラ   │───>│  MediaPipe   │───>│  特徴量抽出     │
│  640x480     │    │  FaceMesh    │    │  EAR/MAR/HeadPose│
└─────────────┘    └──────────────┘    └────────┬────────┘
                                                │
                                       ┌────────v────────┐
                                       │ ルールベース     │──── 95%のケース
                                       │ 分類器           │     (0ms, 決定論的)
                                       └────────┬────────┘
                                                │ 曖昧なケースのみ
                                       ┌────────v────────┐
                                       │ llama-cpp-python │──── 5%のケース
                                       │ Qwen2.5-3B      │     (~650ms)
                                       │ (Q4_K_M, Metal)  │
                                       └────────┬────────┘
                                                │
                              カメラ判定(5s間隔) │
                                                │
                                       ┌────────v────────┐
┌─────────────┐                        │                  │
│  PC利用状況  │──── idle/focused ────>│  統合判定器      │───> 最終状態
│  モニター    │    (30s間隔, 補助)     │                  │
└─────────────┘                        └──────────────────┘
```

---

## 結論

3ラウンド+総合テストの反復的な検証を通じて、**llama-cpp-python + Qwen2.5-3B（テキストモード）** が、精度・レイテンシー・リソース効率・デプロイ容易性の全てにおいて最適であることを確認した。

ルールベース分類器との2段階構成により、95%のケースでLLM呼び出しを回避でき、通常作業への影響を最小限に抑えながらリアルタイムの状態推定が可能となった。

また、総合テストの結果から**カメラ判定をプライマリ、PC利用状況をセカンダリ**とする統合方針を決定した。カメラは身体状態（drowsy/distracted/away）の直接観測に優れ、PC利用状況はidle検出やfocused確認の補助に適している。両者を組み合わせることで、単独では検出困難なケースもカバーできる。
