# 手動テスト結果

# Verify camera pipeline

```bash
python -m shared.camera --show-video --duration 10
```

一度実行すると、Macで許可しますか？と聞かれるので、許可
その間、pythonプロセスはエラーで終わっている。

もう一度実行する。

この段階で、iphoneのカメラに繋がってしまった人は以下のURLを参考に、iphoneのカメラを使わないように設定する。

- https://discussionsjapan.apple.com/thread/254960310?sortBy=rank

macのカメラが緑になれば、接続成功

```bash
python -m experiment3_pcusage.monitor --duration 30
```

許可が必要な可能性がある。実行したら勝手にMacでシステム設定を開くか聞かれるので、許可する。

# シナリオ実行

1. まず 実験1のテキストモード（run_text_llama_cpp → run_text_mlx）から試す。これが最も軽量で動作しやすい
2. 次に 実験2（LM Studioでモデルをロードしてから）
3. ビジョンモードは重いので後回し
4. 実験3は独立しているのでいつでも

### シナリオ別結果

# poc-plan.mdに従ってテストしました

シナリオを各コマンドに対して実行しました。結果を添付します。
基本的には精度が低い結果と感じます。
改良案を検討してください。
特徴量がうまく取れていないのか、LLMの解釈が下手なのか、などの観点があると思います。
二つのエージェントに分かれ、それぞれの観点から分析してもらうのもいいかもしれません。

### python -m experiment1_embedded.run_text_llama_cpp --duration 60 --interval 5

- シナリオA-Dを実行
- 正答率50%くらいでイマイチ
- drowsyとfocusedの区別がついていない
- awayは正しく認識している
- distractedは一度も出てこなかった

### python -m experiment1_embedded.run_text_mlx --duration 60 --interval 5

- シナリオA-Dを実行
- 正答率70%くらい
- ただ、drowsyとfocusedの区別があまりついていない
  - drowsyをfocusedと判定するケースが多い
- awayは正しく認識している
- distractedは一度も出てこなかった

### python -m experiment2_lmstudio.run_text_lmstudio --duration 60 --interval 5

- qwen/qwen3-vl-8bをロード
- シナリオA-Dを実行
- 正答率30%くらいで壊滅的
- 特にずっと集中している顔つきをしていたが、distractedとdrowsyを頻発
- awayの認識はできていた

### python -m experiment1_embedded.run_vision_llama_cpp --duration 120 --interval 15

- シナリオA-Dを実行
- 全てをdrowsyと判定してしまい、全く使い物にならなかった

### python -m experiment1_embedded.run_vision_mlx --duration 120 --interval 15

- sittingとunknownしか出てこない（仕様と異なる？）

### python -m experiment2_lmstudio.run_vision_lmstudio --duration 120 --interval 15

- シナリオA-Dを実行
- 正答率は70%くらい
- 集中したそぶりを見せてもdrowsyと判定されることがある
- 逆にdrowsyの状態でもfocusedと判定されることがある
- distractedとawayは正しく認識している

### python -m experiment3_pcusage.run_analysis --backend lmstudio --duration 300 --interval 30

- シナリオF-Hを実行
- focusedは基本的に正答していました。
- しかし、Idle: 52.2sにもかかわらず、idleとはなりませんでした。
- また、アプリを切り替えまくっていたのですが、distractedとはならず、focusedのままでした。「Reasoning: High keyboard and mouse activity with no app switches or idle time indicates steady, concentrated work in the 'Code' editor.」というログになっていました（実際には他のアプリも使っていたのですが、検出されなかった？）。

# シナリオ実行2回目

2回目を実行しました。
精度はかなり上がってきていると思いますが、テキストベースの場合focusedをdistractedと誤判定してしまうケースが多いです。visionベースの場合はlmstudioで8b以上のモデルを使った時は比較的安定しています。
visionベースかつ8bで精度が出ることは分かりましたが、リソース的に重いのが難点です。もう少し軽量なモデル、もしくはテキストベースで精度が出るようにしたいところです。
調整していたらキリがないとは思いますが、この後はどうすべきでしょうか？改良案を検討してください。

### python -m experiment1_embedded.run_text_llama_cpp --duration 60 --interval 5

- 集中していたら
  - 全てdistractedと判定
- スマホをいじったり、よそ見をしていたら
  - distractedを9回/10回正しく判定（1回だけawayと判定）
- 眠そうにしていたら
  - 全てdrowsyと判定
- 画面外に出たら
  - 全てawayと判定
- まとめると
  - focusedを全てdistractedと誤判定してしまう以外は正しく動作している

### python -m experiment1_embedded.run_text_mlx --duration 60 --interval 5

- 集中していたら
  - 全てdistractedと判定
- スマホをいじったり、よそ見をしていたら
  - 7/10回正しくdistractedと判定、3回awayと判定
- 眠そうにしていたら
  - 全てdrowsyと判定
- 画面外に出たら
  - 全てawayと判定
- まとめると
  - focusedを全てdistractedと誤判定してしまう以外は正しく動作している

### python -m experiment2_lmstudio.run_text_lmstudio --duration 60 --interval 5

- 集中していたら
  - 全てdistractedと判定
- スマホをいじったり、よそ見をしていたら
  - 7/10回正しくdistractedと判定、3回awayと判定
- 眠そうにしていたら
  - 全てdrowsyと判定
- 画面外に出たら
  - 全てawayと判定
- まとめると
  - focusedを全てdistractedと誤判定してしまう以外は正しく動作している
  - google/gemma-3-27bを使用しても同様の結果だったので、モデル依存ではなさそう？

### python -m experiment1_embedded.run_vision_llama_cpp --duration 60 --interval 15

- 集中していたら
  - 全てfocusedと判定
- スマホをいじったり、よそ見をしていたら
  - 3回focused, 1回awayだった
- 眠そうにしていたら
  - 3回focused, 1回awayだった
- 画面外に出たら
  - 全てawayと判定
- まとめると
  - focusedとawayしか認識できていない
  - distractedとdrowsyを全く認識できていない

### python -m experiment1_embedded.run_vision_mlx --duration 60 --interval 15

- unknownとawayしか出てこない
- awayは正しく認識できている

### python -m experiment2_lmstudio.run_vision_lmstudio --duration 60 --interval 15

- 集中していたら
  - 全てfocusedと判定
- スマホをいじったり、よそ見をしていたら
  - focusedとdistracted, drowsy, awayが混在していたがdistractedが多め
- 眠そうにしていたら
  - 全てdrowsyだった
- 画面外に出たら
  - 全てawayと判定
- まとめると
  - 全体的に認識精度が高いが、distractedの認識がやや不安定
  - qwen/qwen3-vl-8bでもgoogle/gemma-3-27bでも同様の結果だったので、2bや3bではダメだけど8b程度あれば十分そう？

### python -m experiment3_pcusage.run_analysis --backend lmstudio --duration 300 --interval 15

- focusedは基本的に正答していました。
- idleはis_idleフラグがあるにもかかわらず、勝手にidle判定する場面があるのでそこはプロンプトで厳格に指示してください（ログを見てみてください）。
- また、distructed判定が厳しい気がします。App switchesとUnique appsが一度増えるとなかなか減らないことが原因かもしれません。実際にはunique appsが1つだけにしているにもかかわらず、5や6のままになっている場面があります。

# シナリオ実行3回目

3回目を実行しました。

### python -m experiment1_embedded.run_text_llama_cpp --duration 60 --interval 5

- 集中していたら
  - ほぼfocusedと判定
  - ただし、最初にdistractedにした場合、その後focusedに戻らずdistractedのままになるケースがあった
- スマホをいじったり、よそ見をしていたら
  - distractedとawayが混在
- 眠そうにしていたら
  - ほぼdrowsyと判定
- 画面外に出たら
  - ほぼawayと判定
- まとめると
  - 全体的に認識精度が高い

### python -m experiment1_embedded.run_text_mlx --duration 60 --interval 5

- 集中していたら
  - ほぼfocusedと判定
  - ただし、最初にdistractedにした場合、その後focusedに戻らずdistractedのままになるケースがあった
- スマホをいじったり、よそ見をしていたら
  - distractedとawayが混在
- 眠そうにしていたら
  - ほぼdrowsyと判定
- 画面外に出たら
  - ほぼawayと判定
- まとめると
  - 全体的に認識精度が高い

### python -m experiment2_lmstudio.run_text_lmstudio --duration 60 --interval 5

- テキスト&組み込みで十分そうなので、やってない

### python -m experiment1_embedded.run_vision_llama_cpp --duration 60 --interval 15

- テキスト&組み込みで十分そうなので、やってない

### python -m experiment1_embedded.run_vision_mlx --duration 60 --interval 15

- テキスト&組み込みで十分そうなので、やってない

### python -m experiment2_lmstudio.run_vision_lmstudio --duration 60 --interval 15

- テキスト&組み込みで十分そうなので、やってない
